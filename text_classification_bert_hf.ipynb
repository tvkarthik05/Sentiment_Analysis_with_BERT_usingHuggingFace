{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
    "# Objective\n",
    "\n",
    "+ Build a sentiment analysis model with huggingface (HF) models (Includes pre-trained & fine-tuning)\n",
    "+ Using HF api's instead of native pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import gc\n",
    "import torch\n",
    "# import mlflow.pytorch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "# from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from transformers import (BertModel, \\\n",
    "BertTokenizer, \\\n",
    "BertConfig,\\\n",
    "AdamW, \\\n",
    "get_linear_schedule_with_warmup, \\\n",
    "pipeline, \\\n",
    "BertForSequenceClassification, \\\n",
    "Trainer, \\\n",
    "TrainingArguments\n",
    ")\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9647619724273682}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('I’ve been signed up for a year and haven’t received a single sample for anything. \\\n",
    "I’d never complain about “free” unless “free” meant nothing at all. lol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2021\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Company public response</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>ZIP code</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Date sent to company</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>Complaint ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>Information belongs to someone else</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CAPITAL ONE FINANCIAL CORPORATION</td>\n",
       "      <td>PA</td>\n",
       "      <td>186XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3274605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>Vehicle loan or lease</td>\n",
       "      <td>Loan</td>\n",
       "      <td>Struggling to pay your loan</td>\n",
       "      <td>Denied request to lower payments</td>\n",
       "      <td>I contacted Ally on Friday XX/XX/XXXX after fa...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>ALLY FINANCIAL INC.</td>\n",
       "      <td>NJ</td>\n",
       "      <td>088XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3425257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>Account status incorrect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>TRANSUNION INTERMEDIATE HOLDINGS, INC.</td>\n",
       "      <td>PA</td>\n",
       "      <td>19067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3198225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-06</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Problem with a credit reporting company's inve...</td>\n",
       "      <td>Was not notified of investigation status or re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EQUIFAX, INC.</td>\n",
       "      <td>MD</td>\n",
       "      <td>21207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>2021-10-06</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4783820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Conventional home mortgage</td>\n",
       "      <td>Trouble during payment process</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>FLAGSTAR BANK, FSB</td>\n",
       "      <td>ID</td>\n",
       "      <td>83706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Referral</td>\n",
       "      <td>2019-08-15</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3342290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date received                                            Product  \\\n",
       "0    2019-06-13  Credit reporting, credit repair services, or o...   \n",
       "1    2019-11-01                              Vehicle loan or lease   \n",
       "2    2019-04-01  Credit reporting, credit repair services, or o...   \n",
       "3    2021-10-06  Credit reporting, credit repair services, or o...   \n",
       "4    2019-08-08                                           Mortgage   \n",
       "\n",
       "                  Sub-product  \\\n",
       "0            Credit reporting   \n",
       "1                        Loan   \n",
       "2            Credit reporting   \n",
       "3            Credit reporting   \n",
       "4  Conventional home mortgage   \n",
       "\n",
       "                                               Issue  \\\n",
       "0               Incorrect information on your report   \n",
       "1                        Struggling to pay your loan   \n",
       "2               Incorrect information on your report   \n",
       "3  Problem with a credit reporting company's inve...   \n",
       "4                     Trouble during payment process   \n",
       "\n",
       "                                           Sub-issue  \\\n",
       "0                Information belongs to someone else   \n",
       "1                   Denied request to lower payments   \n",
       "2                           Account status incorrect   \n",
       "3  Was not notified of investigation status or re...   \n",
       "4                                                NaN   \n",
       "\n",
       "                        Consumer complaint narrative  \\\n",
       "0                                                NaN   \n",
       "1  I contacted Ally on Friday XX/XX/XXXX after fa...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                             Company public response  \\\n",
       "0                                                NaN   \n",
       "1  Company has responded to the consumer and the ...   \n",
       "2  Company has responded to the consumer and the ...   \n",
       "3                                                NaN   \n",
       "4  Company has responded to the consumer and the ...   \n",
       "\n",
       "                                  Company State ZIP code Tags  \\\n",
       "0       CAPITAL ONE FINANCIAL CORPORATION    PA    186XX  NaN   \n",
       "1                     ALLY FINANCIAL INC.    NJ    088XX  NaN   \n",
       "2  TRANSUNION INTERMEDIATE HOLDINGS, INC.    PA    19067  NaN   \n",
       "3                           EQUIFAX, INC.    MD    21207  NaN   \n",
       "4                      FLAGSTAR BANK, FSB    ID    83706  NaN   \n",
       "\n",
       "  Consumer consent provided? Submitted via Date sent to company  \\\n",
       "0       Consent not provided           Web           2019-06-13   \n",
       "1           Consent provided           Web           2019-11-01   \n",
       "2       Consent not provided           Web           2019-04-01   \n",
       "3                        NaN           Web           2021-10-06   \n",
       "4                        NaN      Referral           2019-08-15   \n",
       "\n",
       "  Company response to consumer Timely response? Consumer disputed?  \\\n",
       "0      Closed with explanation              Yes                NaN   \n",
       "1      Closed with explanation              Yes                NaN   \n",
       "2      Closed with explanation              Yes                NaN   \n",
       "3      Closed with explanation              Yes                NaN   \n",
       "4      Closed with explanation              Yes                NaN   \n",
       "\n",
       "   Complaint ID  \n",
       "0       3274605  \n",
       "1       3425257  \n",
       "2       3198225  \n",
       "3       4783820  \n",
       "4       3342290  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_org = pd.read_csv(\"./complaints_small.csv\", nrows=5000)\n",
    "print(df_org.shape)\n",
    "df_org.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe size -  (2593, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I contacted Ally on Friday XX/XX/XXXX after fa...</td>\n",
       "      <td>Vehicle loan or lease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello This complaint is against the three cred...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am a victim of Identity Theft &amp; currently ha...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two accounts are still on my credit history af...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Receiving daily telephone call ( s ) from XXXX...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  I contacted Ally on Friday XX/XX/XXXX after fa...   \n",
       "1  Hello This complaint is against the three cred...   \n",
       "2  I am a victim of Identity Theft & currently ha...   \n",
       "3  Two accounts are still on my credit history af...   \n",
       "4  Receiving daily telephone call ( s ) from XXXX...   \n",
       "\n",
       "                                              target  \n",
       "0                              Vehicle loan or lease  \n",
       "1  Credit reporting, credit repair services, or o...  \n",
       "2  Credit reporting, credit repair services, or o...  \n",
       "3  Credit reporting, credit repair services, or o...  \n",
       "4  Credit reporting, credit repair services, or o...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_org.loc[(df_org['Consumer complaint narrative'].notnull()), ['Consumer complaint narrative', 'Product']].copy().reset_index().drop('index', axis = 1)\n",
    "df.columns = ['text', 'target']\n",
    "print('Dataframe size - ', df.shape)\n",
    "df.head()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Credit reporting, credit repair services, or other personal consumer reports    1118\n",
       "Debt collection                                                                  474\n",
       "Credit card or prepaid card                                                      285\n",
       "Mortgage                                                                         242\n",
       "Checking or savings account                                                      181\n",
       "Student loan                                                                     116\n",
       "Vehicle loan or lease                                                             63\n",
       "Money transfer, virtual currency, or money service                                57\n",
       "Payday loan, title loan, or personal loan                                         44\n",
       "Credit reporting                                                                   4\n",
       "Consumer Loan                                                                      3\n",
       "Money transfers                                                                    2\n",
       "Credit card                                                                        2\n",
       "Bank account or service                                                            2\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Credit reporting, credit repair services, or other personal consumer reports',\n",
       " 'Debt collection',\n",
       " 'Credit card or prepaid card',\n",
       " 'Mortgage',\n",
       " 'Checking or savings account',\n",
       " 'Student loan',\n",
       " 'Vehicle loan or lease',\n",
       " 'Money transfer, virtual currency, or money service',\n",
       " 'Payday loan, title loan, or personal loan',\n",
       " 'Credit reporting',\n",
       " 'Consumer Loan',\n",
       " 'Money transfers',\n",
       " 'Credit card',\n",
       " 'Bank account or service']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = list(df.target.value_counts().index)\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Credit reporting, credit repair services, or other personal consumer reports': 0,\n",
       " 'Debt collection': 1,\n",
       " 'Credit card or prepaid card': 2,\n",
       " 'Mortgage': 3,\n",
       " 'Checking or savings account': 4,\n",
       " 'Student loan': 5,\n",
       " 'Vehicle loan or lease': 6,\n",
       " 'Money transfer, virtual currency, or money service': 7,\n",
       " 'Payday loan, title loan, or personal loan': 8,\n",
       " 'Credit reporting': 9,\n",
       " 'Consumer Loan': 10,\n",
       " 'Money transfers': 11,\n",
       " 'Credit card': 12,\n",
       " 'Bank account or service': 13}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {}\n",
    "for i in range(len(unique_labels)):\n",
    "    label_dict[unique_labels[i]] = i\n",
    "\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I contacted Ally on Friday XX/XX/XXXX after fa...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello This complaint is against the three cred...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am a victim of Identity Theft &amp; currently ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two accounts are still on my credit history af...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Receiving daily telephone call ( s ) from XXXX...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  I contacted Ally on Friday XX/XX/XXXX after fa...       6\n",
       "1  Hello This complaint is against the three cred...       0\n",
       "2  I am a victim of Identity Theft & currently ha...       0\n",
       "3  Two accounts are still on my credit history af...       0\n",
       "4  Receiving daily telephone call ( s ) from XXXX...       0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target = df.target.replace(label_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(df['text'])\n",
    "y = list(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = np.unique(df.target)\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = len(class_names)\n",
    "MAX_LEN = 160\n",
    "\n",
    "TEST_SIZE = 0.1\n",
    "VAL_SIZE = 0.5\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "DROPOUT = 0.3\n",
    "EPOCHS = 1\n",
    "\n",
    "\n",
    "MODEL_CLASSES = {'bert': (BertConfig, BertForSequenceClassification, BertTokenizer, 'bert-base-cased')}\n",
    "\n",
    "SELECTED_MODEL_CLASS = 'bert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_class, model_class, tokenizer_class, pretrained_model = MODEL_CLASSES[SELECTED_MODEL_CLASS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at C:\\Users\\Karthik/.cache\\huggingface\\transformers\\6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at C:\\Users\\Karthik/.cache\\huggingface\\transformers\\ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at C:\\Users\\Karthik/.cache\\huggingface\\transformers\\226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n",
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at C:\\Users\\Karthik/.cache\\huggingface\\transformers\\a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(pretrained_model, return_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at C:\\Users\\Karthik/.cache\\huggingface\\transformers\\a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at C:\\Users\\Karthik/.cache\\huggingface\\transformers\\092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = model_class.from_pretrained(\\\n",
    "pretrained_model, # Use the 12-layer BERT model, with an cased vocab.\\\n",
    "num_labels = N_CLASSES, # The number of output labels--2 for binary classification.\\\n",
    "output_attentions = False, # Whether the model returns attentions weights.\\\n",
    "output_hidden_states = False, # Whether the model returns all hidden-states.\\\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell pytorch to run this model on the GPU.\n",
    "# model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(X_train, padding=True, truncation=True, max_length=MAX_LEN)\n",
    "val_encodings = tokenizer(X_val, padding=True, truncation=True, max_length=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_encodings['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert our tokenized data into a torch Dataset\n",
    "train_dataset = PrepareDataset(train_encodings, y_train)\n",
    "val_dataset = PrepareDataset(val_encodings, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1) # Gets the rowwise maximum value position\n",
    "    # calculate accuracy using sklearn's function\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=preds)\n",
    "    recall = recall_score(y_true=labels, y_pred=preds, average='macro')\n",
    "    precision = precision_score(y_true=labels, y_pred=preds, average='macro')\n",
    "    f1 = f1_score(y_true=labels, y_pred=preds, average='macro')\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 100\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments( \\\n",
    "\toutput_dir='./results', \\\n",
    "\tnum_train_epochs=EPOCHS,\\\n",
    "\tper_device_train_batch_size=BATCH_SIZE, \\\n",
    "\tper_device_eval_batch_size=BATCH_SIZE, \\\n",
    "\twarmup_steps=100, \\\n",
    "\tweight_decay=0.01, \\\n",
    "\tlogging_dir='./logs', \\\n",
    "\tload_best_model_at_end=True, \\\n",
    "\tevaluation_strategy=\"steps\", \\\n",
    "\tlogging_steps=100, \\\n",
    "\tsave_steps=100 \\\n",
    ")\n",
    "# warmup_steps: Number of steps used for a linear warmup from 0 to learning_rate\n",
    "# evaluation_strategy: Number of update steps between two evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "model=model, \\\n",
    "args=training_args, \\\n",
    "train_dataset=train_dataset, \\\n",
    "eval_dataset=val_dataset,\\\n",
    "compute_metrics=compute_metrics, \\\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2074\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 56:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.038800</td>\n",
       "      <td>1.424462</td>\n",
       "      <td>0.589595</td>\n",
       "      <td>0.297917</td>\n",
       "      <td>0.279778</td>\n",
       "      <td>0.246077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.204900</td>\n",
       "      <td>1.030066</td>\n",
       "      <td>0.693642</td>\n",
       "      <td>0.346009</td>\n",
       "      <td>0.371583</td>\n",
       "      <td>0.355845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 8\n",
      "C:\\Users\\Karthik\\Programs\\Anaconda3\\envs\\sachin\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./results\\checkpoint-100\n",
      "Configuration saved in ./results\\checkpoint-100\\config.json\n",
      "Model weights saved in ./results\\checkpoint-100\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 8\n",
      "C:\\Users\\Karthik\\Programs\\Anaconda3\\envs\\sachin\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./results\\checkpoint-200\n",
      "Configuration saved in ./results\\checkpoint-200\\config.json\n",
      "Model weights saved in ./results\\checkpoint-200\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results\\checkpoint-200 (score: 1.030065655708313).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=260, training_loss=1.4783022953913763, metrics={'train_runtime': 3427.7384, 'train_samples_per_second': 0.605, 'train_steps_per_second': 0.076, 'total_flos': 170547226072320.0, 'train_loss': 1.4783022953913763, 'epoch': 1.0})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mlflow.end_run()\n",
    "trainer.train()\n",
    "\n",
    "# The loss function here is CrossEntropyLoss = -summation(ti * log(pi)) where ti is the binary truth label and pi is the softmax probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [65/65 03:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karthik\\Programs\\Anaconda3\\envs\\sachin\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.030065655708313,\n",
       " 'eval_accuracy': 0.6936416184971098,\n",
       " 'eval_precision': 0.3460093604668385,\n",
       " 'eval_recall': 0.371582907127797,\n",
       " 'eval_f1': 0.3558451522345688,\n",
       " 'eval_runtime': 223.1035,\n",
       " 'eval_samples_per_second': 2.326,\n",
       " 'eval_steps_per_second': 0.291,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in sentiment-bert-base-cased\\config.json\n",
      "Model weights saved in sentiment-bert-base-cased\\pytorch_model.bin\n",
      "tokenizer config file saved in sentiment-bert-base-cased\\tokenizer_config.json\n",
      "Special tokens file saved in sentiment-bert-base-cased\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('sentiment-bert-base-cased\\\\tokenizer_config.json',\n",
       " 'sentiment-bert-base-cased\\\\special_tokens_map.json',\n",
       " 'sentiment-bert-base-cased\\\\vocab.txt',\n",
       " 'sentiment-bert-base-cased\\\\added_tokens.json')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving the fine tuned model & tokenizer\n",
    "\n",
    "model_path = \"sentiment-\"+pretrained_model\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file sentiment-bert-base-cased\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.12.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file sentiment-bert-base-cased\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at sentiment-bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_load = model_class.from_pretrained(model_path, num_labels=N_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on Raw Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "'MAX_LEN':MAX_LEN,\n",
    "'TARGETS':class_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(text, model, config):\n",
    "    # prepare our text into tokenized sequence\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=config['MAX_LEN'], return_tensors=\"pt\")\n",
    "    tokenizer(X_train, padding=True, truncation=True, max_length=MAX_LEN)\n",
    "    # perform inference to our model\n",
    "    outputs = model(**inputs)\n",
    "    # get output probabilities by doing softmax\n",
    "    probs = outputs[0].softmax(1)\n",
    "    # executing argmax function to get the candidate label\n",
    "    return config['TARGETS'][probs.argmax()], probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_text = \"I love completing my todos! Best app ever!!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " tensor([[0.4695, 0.1020, 0.1665, 0.0459, 0.0616, 0.0516, 0.0276, 0.0164, 0.0144,\n",
       "          0.0071, 0.0168, 0.0064, 0.0079, 0.0061]], grad_fn=<SoftmaxBackward>))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(review_text, model_load, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe1f8cf8aef415bf8d1ca74cc522c917ba79e26aa36f05c4c8e36afcfaf0b9c5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('sachin': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
