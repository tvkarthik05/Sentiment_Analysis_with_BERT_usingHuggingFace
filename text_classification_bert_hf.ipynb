{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "+ Build a sentiment analysis model with huggingface (HF) models (Includes pre-trained & fine-tuning)\n",
    "+ Using HF api's instead of native pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import gc\n",
    "import torch\n",
    "# import mlflow.pytorch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "# from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from transformers import (BertModel, \\\n",
    "BertTokenizer, \\\n",
    "BertConfig,\\\n",
    "AdamW, \\\n",
    "get_linear_schedule_with_warmup, \\\n",
    "pipeline, \\\n",
    "BertForSequenceClassification, \\\n",
    "Trainer, \\\n",
    "TrainingArguments\n",
    ")\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for cuda on the machine\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pre-trained HF pipeline for sentiment analysis\n",
    "classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9647619724273682}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('I’ve been signed up for a year and haven’t received a single sample for anything. \\\n",
    "I’d never complain about “free” unless “free” meant nothing at all. lol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seeds for reproducibility of results\n",
    "SEED = 2021\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Company public response</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>ZIP code</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Date sent to company</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>Complaint ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13-06-2019</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>Information belongs to someone else</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CAPITAL ONE FINANCIAL CORPORATION</td>\n",
       "      <td>PA</td>\n",
       "      <td>186XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>13-06-2019</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3274605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-11-2019</td>\n",
       "      <td>Vehicle loan or lease</td>\n",
       "      <td>Loan</td>\n",
       "      <td>Struggling to pay your loan</td>\n",
       "      <td>Denied request to lower payments</td>\n",
       "      <td>I contacted Ally on Friday XX/XX/XXXX after fa...</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>ALLY FINANCIAL INC.</td>\n",
       "      <td>NJ</td>\n",
       "      <td>088XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>01-11-2019</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3425257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-04-2019</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>Account status incorrect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>TRANSUNION INTERMEDIATE HOLDINGS, INC.</td>\n",
       "      <td>PA</td>\n",
       "      <td>19067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>01-04-2019</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3198225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06-10-2021</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Problem with a credit reporting company's inve...</td>\n",
       "      <td>Was not notified of investigation status or re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EQUIFAX, INC.</td>\n",
       "      <td>MD</td>\n",
       "      <td>21207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>06-10-2021</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4783820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-08-2019</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Conventional home mortgage</td>\n",
       "      <td>Trouble during payment process</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>FLAGSTAR BANK, FSB</td>\n",
       "      <td>ID</td>\n",
       "      <td>83706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Referral</td>\n",
       "      <td>15-08-2019</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3342290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date received                                            Product  \\\n",
       "0    13-06-2019  Credit reporting, credit repair services, or o...   \n",
       "1    01-11-2019                              Vehicle loan or lease   \n",
       "2    01-04-2019  Credit reporting, credit repair services, or o...   \n",
       "3    06-10-2021  Credit reporting, credit repair services, or o...   \n",
       "4    08-08-2019                                           Mortgage   \n",
       "\n",
       "                  Sub-product  \\\n",
       "0            Credit reporting   \n",
       "1                        Loan   \n",
       "2            Credit reporting   \n",
       "3            Credit reporting   \n",
       "4  Conventional home mortgage   \n",
       "\n",
       "                                               Issue  \\\n",
       "0               Incorrect information on your report   \n",
       "1                        Struggling to pay your loan   \n",
       "2               Incorrect information on your report   \n",
       "3  Problem with a credit reporting company's inve...   \n",
       "4                     Trouble during payment process   \n",
       "\n",
       "                                           Sub-issue  \\\n",
       "0                Information belongs to someone else   \n",
       "1                   Denied request to lower payments   \n",
       "2                           Account status incorrect   \n",
       "3  Was not notified of investigation status or re...   \n",
       "4                                                NaN   \n",
       "\n",
       "                        Consumer complaint narrative  \\\n",
       "0                                                NaN   \n",
       "1  I contacted Ally on Friday XX/XX/XXXX after fa...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                             Company public response  \\\n",
       "0                                                NaN   \n",
       "1  Company has responded to the consumer and the ...   \n",
       "2  Company has responded to the consumer and the ...   \n",
       "3                                                NaN   \n",
       "4  Company has responded to the consumer and the ...   \n",
       "\n",
       "                                  Company State ZIP code Tags  \\\n",
       "0       CAPITAL ONE FINANCIAL CORPORATION    PA    186XX  NaN   \n",
       "1                     ALLY FINANCIAL INC.    NJ    088XX  NaN   \n",
       "2  TRANSUNION INTERMEDIATE HOLDINGS, INC.    PA    19067  NaN   \n",
       "3                           EQUIFAX, INC.    MD    21207  NaN   \n",
       "4                      FLAGSTAR BANK, FSB    ID    83706  NaN   \n",
       "\n",
       "  Consumer consent provided? Submitted via Date sent to company  \\\n",
       "0       Consent not provided           Web           13-06-2019   \n",
       "1           Consent provided           Web           01-11-2019   \n",
       "2       Consent not provided           Web           01-04-2019   \n",
       "3                        NaN           Web           06-10-2021   \n",
       "4                        NaN      Referral           15-08-2019   \n",
       "\n",
       "  Company response to consumer Timely response? Consumer disputed?  \\\n",
       "0      Closed with explanation              Yes                NaN   \n",
       "1      Closed with explanation              Yes                NaN   \n",
       "2      Closed with explanation              Yes                NaN   \n",
       "3      Closed with explanation              Yes                NaN   \n",
       "4      Closed with explanation              Yes                NaN   \n",
       "\n",
       "   Complaint ID  \n",
       "0       3274605  \n",
       "1       3425257  \n",
       "2       3198225  \n",
       "3       4783820  \n",
       "4       3342290  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_org = pd.read_csv(\"./complaints_small.csv\", nrows=5000)\n",
    "print(df_org.shape)\n",
    "df_org.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe size -  (2593, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I contacted Ally on Friday XX/XX/XXXX after fa...</td>\n",
       "      <td>Vehicle loan or lease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello This complaint is against the three cred...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am a victim of Identity Theft &amp; currently ha...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two accounts are still on my credit history af...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Receiving daily telephone call ( s ) from XXXX...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  I contacted Ally on Friday XX/XX/XXXX after fa...   \n",
       "1  Hello This complaint is against the three cred...   \n",
       "2  I am a victim of Identity Theft & currently ha...   \n",
       "3  Two accounts are still on my credit history af...   \n",
       "4  Receiving daily telephone call ( s ) from XXXX...   \n",
       "\n",
       "                                              target  \n",
       "0                              Vehicle loan or lease  \n",
       "1  Credit reporting, credit repair services, or o...  \n",
       "2  Credit reporting, credit repair services, or o...  \n",
       "3  Credit reporting, credit repair services, or o...  \n",
       "4  Credit reporting, credit repair services, or o...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Considering only 2 cols which we need for our modelling\n",
    "df = df_org.loc[(df_org['Consumer complaint narrative'].notnull()), ['Consumer complaint narrative', 'Product']].copy().reset_index().drop('index', axis = 1)\n",
    "df.columns = ['text', 'target']\n",
    "print('Dataframe size - ', df.shape)\n",
    "df.head()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Credit reporting, credit repair services, or other personal consumer reports    1118\n",
       "Debt collection                                                                  474\n",
       "Credit card or prepaid card                                                      285\n",
       "Mortgage                                                                         242\n",
       "Checking or savings account                                                      181\n",
       "Student loan                                                                     116\n",
       "Vehicle loan or lease                                                             63\n",
       "Money transfer, virtual currency, or money service                                57\n",
       "Payday loan, title loan, or personal loan                                         44\n",
       "Credit reporting                                                                   4\n",
       "Consumer Loan                                                                      3\n",
       "Money transfers                                                                    2\n",
       "Credit card                                                                        2\n",
       "Bank account or service                                                            2\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Credit reporting, credit repair services, or other personal consumer reports',\n",
       " 'Debt collection',\n",
       " 'Credit card or prepaid card',\n",
       " 'Mortgage',\n",
       " 'Checking or savings account',\n",
       " 'Student loan',\n",
       " 'Vehicle loan or lease',\n",
       " 'Money transfer, virtual currency, or money service',\n",
       " 'Payday loan, title loan, or personal loan',\n",
       " 'Credit reporting',\n",
       " 'Consumer Loan',\n",
       " 'Money transfers',\n",
       " 'Credit card',\n",
       " 'Bank account or service']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = list(df.target.value_counts().index)\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Credit reporting, credit repair services, or other personal consumer reports': 0,\n",
       " 'Debt collection': 1,\n",
       " 'Credit card or prepaid card': 2,\n",
       " 'Mortgage': 3,\n",
       " 'Checking or savings account': 4,\n",
       " 'Student loan': 5,\n",
       " 'Vehicle loan or lease': 6,\n",
       " 'Money transfer, virtual currency, or money service': 7,\n",
       " 'Payday loan, title loan, or personal loan': 8,\n",
       " 'Credit reporting': 9,\n",
       " 'Consumer Loan': 10,\n",
       " 'Money transfers': 11,\n",
       " 'Credit card': 12,\n",
       " 'Bank account or service': 13}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create numeric labels as training cannot be done on string type\n",
    "label_dict = {}\n",
    "for i in range(len(unique_labels)):\n",
    "    label_dict[unique_labels[i]] = i\n",
    "\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I contacted Ally on Friday XX/XX/XXXX after fa...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello This complaint is against the three cred...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am a victim of Identity Theft &amp; currently ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two accounts are still on my credit history af...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Receiving daily telephone call ( s ) from XXXX...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  I contacted Ally on Friday XX/XX/XXXX after fa...       6\n",
       "1  Hello This complaint is against the three cred...       0\n",
       "2  I am a victim of Identity Theft & currently ha...       0\n",
       "3  Two accounts are still on my credit history af...       0\n",
       "4  Receiving daily telephone call ( s ) from XXXX...       0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the target variable value with numeric dictionary\n",
    "df.target = df.target.replace(label_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(df['text'])\n",
    "y = list(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = np.unique(df.target)\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = len(class_names) # No. of classes of target variable\n",
    "MAX_LEN = 160 # Max length for the text to be allowed\n",
    "\n",
    "TEST_SIZE = 0.1 # Test data proportion\n",
    "VAL_SIZE = 0.5 # Validation data proportion\n",
    "\n",
    "BATCH_SIZE = 8 # Batch size for each iteration\n",
    "DROPOUT = 0.3 # Dropout for introducing regularization\n",
    "EPOCHS = 1 # No. of epochs\n",
    "\n",
    "# BERT modules required for configurtion, Classification & Tokenization\n",
    "MODEL_CLASSES = {'bert': (BertConfig, BertForSequenceClassification, BertTokenizer, 'bert-base-cased')}\n",
    "\n",
    "SELECTED_MODEL_CLASS = 'bert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the BERT modules into objects\n",
    "config_class, model_class, tokenizer_class, pretrained_model = MODEL_CLASSES[SELECTED_MODEL_CLASS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The tokenizer is a BERT tokenizer which converts the text to tokens\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_model, return_dict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = model_class.from_pretrained(\\\n",
    "pretrained_model, # Use the 12-layer BERT model, with an cased vocab.\\\n",
    "num_labels = N_CLASSES, # The number of output labels--2 for binary classification.\\\n",
    "output_attentions = False, # Whether the model returns attentions weights.\\\n",
    "output_hidden_states = False, # Whether the model returns all hidden-states.\\\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell pytorch to run this model on the GPU.\n",
    "# model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the tokenizer on the train and val data alongwith padding, truncation and max length\n",
    "train_encodings = tokenizer(X_train, padding=True, truncation=True, max_length=MAX_LEN)\n",
    "val_encodings = tokenizer(X_val, padding=True, truncation=True, max_length=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_encodings['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataset into tensors for modelling\n",
    "class PrepareDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our tokenized data into a torch Dataset\n",
    "train_dataset = PrepareDataset(train_encodings, y_train)\n",
    "val_dataset = PrepareDataset(val_encodings, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.PrepareDataset at 0x1c5014abee0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute model metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1) # Gets the rowwise maximum value position\n",
    "    # calculate accuracy using sklearn's function\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=preds)\n",
    "    recall = recall_score(y_true=labels, y_pred=preds, average='macro')\n",
    "    precision = precision_score(y_true=labels, y_pred=preds, average='macro')\n",
    "    f1 = f1_score(y_true=labels, y_pred=preds, average='macro')\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 100\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments( \\\n",
    "\toutput_dir='./results', \\\n",
    "\tnum_train_epochs=EPOCHS,\\\n",
    "\tper_device_train_batch_size=BATCH_SIZE, \\\n",
    "\tper_device_eval_batch_size=BATCH_SIZE, \\\n",
    "\twarmup_steps=100, \\\n",
    "\tweight_decay=0.01, \\\n",
    "\tlogging_dir='./logs', \\\n",
    "\tload_best_model_at_end=True, \\\n",
    "\tevaluation_strategy=\"steps\", \\\n",
    "\tlogging_steps=100, \\\n",
    "\tsave_steps=100 \\\n",
    ")\n",
    "# warmup_steps: Number of steps used for a linear warmup from 0 to learning_rate\n",
    "# evaluation_strategy: Number of update steps between two evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a trainer object\n",
    "trainer = Trainer(\n",
    "model=model, \\\n",
    "args=training_args, \\\n",
    "train_dataset=train_dataset, \\\n",
    "eval_dataset=val_dataset,\\\n",
    "compute_metrics=compute_metrics, \\\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear grabage/cache\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2074\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 56:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.038800</td>\n",
       "      <td>1.424462</td>\n",
       "      <td>0.589595</td>\n",
       "      <td>0.297917</td>\n",
       "      <td>0.279778</td>\n",
       "      <td>0.246077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.204900</td>\n",
       "      <td>1.030066</td>\n",
       "      <td>0.693642</td>\n",
       "      <td>0.346009</td>\n",
       "      <td>0.371583</td>\n",
       "      <td>0.355845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 8\n",
      "C:\\Users\\Karthik\\Programs\\Anaconda3\\envs\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./results\\checkpoint-100\n",
      "Configuration saved in ./results\\checkpoint-100\\config.json\n",
      "Model weights saved in ./results\\checkpoint-100\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 8\n",
      "C:\\Users\\Karthik\\Programs\\Anaconda3\\envs\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./results\\checkpoint-200\n",
      "Configuration saved in ./results\\checkpoint-200\\config.json\n",
      "Model weights saved in ./results\\checkpoint-200\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results\\checkpoint-200 (score: 1.030065655708313).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=260, training_loss=1.4783022953913763, metrics={'train_runtime': 3427.7384, 'train_samples_per_second': 0.605, 'train_steps_per_second': 0.076, 'total_flos': 170547226072320.0, 'train_loss': 1.4783022953913763, 'epoch': 1.0})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trigger the model training\n",
    "# mlflow.end_run()\n",
    "trainer.train()\n",
    "\n",
    "# The loss function here is CrossEntropyLoss = -summation(ti * log(pi)) where ti is the binary truth label and pi is the softmax probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 519\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='65' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [65/65 03:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karthik\\Programs\\Anaconda3\\envs\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.030065655708313,\n",
       " 'eval_accuracy': 0.6936416184971098,\n",
       " 'eval_precision': 0.3460093604668385,\n",
       " 'eval_recall': 0.371582907127797,\n",
       " 'eval_f1': 0.3558451522345688,\n",
       " 'eval_runtime': 223.1035,\n",
       " 'eval_samples_per_second': 2.326,\n",
       " 'eval_steps_per_second': 0.291,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in sentiment-bert-base-cased\\config.json\n",
      "Model weights saved in sentiment-bert-base-cased\\pytorch_model.bin\n",
      "tokenizer config file saved in sentiment-bert-base-cased\\tokenizer_config.json\n",
      "Special tokens file saved in sentiment-bert-base-cased\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('sentiment-bert-base-cased\\\\tokenizer_config.json',\n",
       " 'sentiment-bert-base-cased\\\\special_tokens_map.json',\n",
       " 'sentiment-bert-base-cased\\\\vocab.txt',\n",
       " 'sentiment-bert-base-cased\\\\added_tokens.json')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the fine tuned model & tokenizer\n",
    "model_path = \"sentiment-\"+pretrained_model\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file sentiment-bert-base-cased\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.12.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file sentiment-bert-base-cased\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at sentiment-bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model_load = model_class.from_pretrained(model_path, num_labels=N_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on Raw Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the configs used for training\n",
    "config = {\n",
    "'MAX_LEN':MAX_LEN,\n",
    "'TARGETS':class_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(text, model, config):\n",
    "    # prepare our text into tokenized sequence\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=config['MAX_LEN'], return_tensors=\"pt\")\n",
    "    tokenizer(X_train, padding=True, truncation=True, max_length=MAX_LEN)\n",
    "    # perform inference to our model\n",
    "    outputs = model(**inputs)\n",
    "    # get output probabilities by doing softmax\n",
    "    probs = outputs[0].softmax(1)\n",
    "    # executing argmax function to get the candidate label\n",
    "    return config['TARGETS'][probs.argmax()], probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New text for prediction\n",
    "review_text = \"I love completing my todos! Best app ever!!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " tensor([[0.4695, 0.1020, 0.1665, 0.0459, 0.0616, 0.0516, 0.0276, 0.0164, 0.0144,\n",
       "          0.0071, 0.0168, 0.0064, 0.0079, 0.0061]], grad_fn=<SoftmaxBackward>))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict\n",
    "get_prediction(review_text, model_load, config)\n",
    "\n",
    "# The output is class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe1f8cf8aef415bf8d1ca74cc522c917ba79e26aa36f05c4c8e36afcfaf0b9c5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
